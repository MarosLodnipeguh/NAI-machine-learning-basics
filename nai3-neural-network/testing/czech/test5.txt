Učení bez učitele
Na rozdíl od učení s učitelem trénovací data při učení bez učitele nemají vstupní data provázaná s cílovými proměnnými (ohodnocením, závisle proměnnou...), tj. schází výrok učitele a učení bez učitele tedy vykazuje samoorganizaci, která zachycuje vzory jako hustotu pravděpodobnosti.[29] Učení bez učitele si tedy lze představit jako kompresi vstupních dat, např. například snížení jejich dimense (v analýze hlavních komponent) nebo jejich redukci na diskrétní body (jako je tomu ve shlukové analýze, kde vstupní data reprezentujeme označenými shluky), či jejich vyhlazení (odhad distribučních funkcí). U neuronových sítí se učení bez učitele užívá typicky u kompetičních sítí. Při učení bez učitele nevyhodnocujeme správnost výsledku. Při tomto učení nám vyžadovaný výsledek není znám. Síť dostává na vstup sadu vzorů, které si sama třídí přizpůsobením své topologie. Vzory třídí do skupin a reaguje dle jejich typického zástupce.[30]

Pozn.: Kombinaci učení s učitelem a učení bez učitele označujeme jako semi-supervised learning.

Hebbovské učení
Hebbův[31] princip učení lze popsat jako metodu určování, jak měnit váhy mezi umělými neurony. Váha mezi dvěma neurony se zvyšuje, pokud se oba neurony aktivují současně, a snižuje, pokud se aktivují odděleně. Uzly, které mají tendenci být buď oba pozitivní, nebo oba negativní současně, mají silné pozitivní váhy, zatímco ty, které mají tendenci být opačné, mají silné negativní váhy. Hebbovské učení se užívá u asociativních pamětí, jako je Hopfieldova či bidirektní síť.

Přeučení
Přeučení je stav, kdy je systém příliš přizpůsoben množině trénovacích dat, ale nemá schopnost generalizace a selhává na validační množině dat. To se může stát např. při malém rozsahu trénovací množiny nebo pokud je systém příliš komplexní, např. příliš mnoho skrytých neuronů v neuronové síti. Řešením je zvětšení trénovací množiny, snížení složitosti systému nebo různé techniky regularizace, jako je zavedení náhodného šumu (což v zásadě odpovídá rozšíření trénovací množiny), zavedení omezení na parametry systému, které v důsledku snižuje složitost popisu naučené funkce, nebo předčasné ukončení učení (průběžné sledování chyby na validační množině a konec učení ve chvíli, kdy se chyba na této množině dostane do svého minima).